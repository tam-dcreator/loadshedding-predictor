{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Shedding Classifier Accuracy Calculation\n",
    "\n",
    "This notebook calculates the accuracy, recall, and F1 score for a load shedding classifier. It compares the predicted load shedding values with the actual values and computes various error metrics.\n",
    "\n",
    "## Steps:\n",
    "1. Load the predicted and actual load shedding datasets.\n",
    "2. Ensure the timestamps in both datasets match properly.\n",
    "3. Merge the datasets on the timestamp to align actual and predicted values.\n",
    "4. Extract the actual and predicted values.\n",
    "5. Compute accuracy, recall, and F1 score.\n",
    "6. Compute false positives and false negatives.\n",
    "7. Return the computed metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.38278388278388276,\n",
       " 'recall': 0.7724550898203593,\n",
       " 'f1_score': 0.16064757160647572,\n",
       " 'False Negatives': 38}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix\n",
    "from data_ingestion import read_from_CSV\n",
    "\n",
    "# Load the datasets\n",
    "loadshedding_predicted_path = \"./loadshedding_pred.csv\"\n",
    "loadshedding_actual_path = \"./loadshedding_jan_mar_2024.csv\"\n",
    "\n",
    "loadshedding_pred = read_from_CSV(loadshedding_predicted_path)\n",
    "loadshedding_actual = read_from_CSV(loadshedding_actual_path)\n",
    "\n",
    "# Ensure timestamps match properly\n",
    "loadshedding_pred['date_time'] = pd.to_datetime(loadshedding_pred['date_time'])\n",
    "loadshedding_actual[\"date_time\"] = pd.to_datetime(loadshedding_actual[\"Date\"] + \" \" + loadshedding_actual[\"Hour\"].astype(str) + \":00\", format=\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "# Merge datasets on date_time to align actual and predicted values\n",
    "merged_data = pd.merge(loadshedding_pred, loadshedding_actual, on=\"date_time\", how=\"left\")\n",
    "\n",
    "merged_data.drop(columns=[\"Date\", \"Hour\", \"Unnamed: 0\"], inplace=True)\n",
    "merged_data.columns = merged_data.columns.str.lower()\n",
    "merged_data[\"load_shedding\"] = merged_data[\"load_shedding_stage\"].apply(lambda x: 1 if x not in [\"Unknown\", \"No Load Shedding\"] else 0)\n",
    "\n",
    "# Extract actual and predicted values\n",
    "y_true = merged_data[\"load_shedding\"]\n",
    "y_pred = merged_data[\"estimated_loadshedding\"]\n",
    "\n",
    "# Compute error metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# Compute false positives and false negatives\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "# Return the computed metrics\n",
    "results = {\n",
    "    \"Accuracy\": accuracy,\n",
    "    \"recall\": recall,\n",
    "    \"f1_score\": f1,\n",
    "    \"False Negatives\": fn # focusing more on false negatives since the scrapped +ve true values are the only trusted loadshedding data we have\n",
    "}\n",
    "results\n",
    "# merged_data[\"estimated_loadshedding\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jupyter_Books_Testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
